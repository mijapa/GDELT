Automatically generated by Mendeley Desktop 1.19.6
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop

@article{Yuan2017,
    abstract = {The development of theories and techniques for big data analytics offers tremendous possibility for investigating large-scale events and patterns that emerge over space and time. In this research, we utilize a unique open dataset “The Global Data on Events, Location and Tone” (GDELT) to model the image of China in mass media, specifically, how China has related to the rest of the world and how this connection has evolved upon time. The results of this research contribute to both the methodological and the empirical perspectives: We examined the effectiveness of the dynamic time warping (DTW) distances in measuring the differences between long-term mass media data. We identified four types of connection strength patterns between China and its top 15 related countries. With that, the distance decay effect in mass media is also examined and compared with social media and public transportation data. While using multiple datasets and focusing on mass media, this study generates valuable input regarding the interpretation of the diplomatic and regional correlation for the nation of China. It also provides methodological references for investigating international relations in other countries and regions in the big data era.},
    author = {Yuan, Yihong and Liu, Yu and Wei, Guixing},
    doi = {10.1016/j.compenvurbsys.2016.10.012},
    issn = {01989715},
    journal = {Computers, Environment and Urban Systems},
    keywords = {GDELT,Inter-country relations,Mass media events,Spatio-temporal data mining,Time series},
    pages = {86--96},
    title = {{Exploring inter-country connection in mass media: A case study of China}},
    volume = {62},
    year = {2017}
}
@misc{BigQuery2014,
    title = {{World's largest event dataset now publicly available in BigQuery}},
    url = {https://cloudplatform.googleblog.com/2014/05/worlds-largest-event-dataset-now-publicly-available-in-google-bigquery.html},
    urldate = {2020-06-15},
    year = {2014}
}
@misc{geopandas,
    title = {{GeoPandas}},
    url = {geopandas.org},
    urldate = {2020-06-29}
}
@misc{gdelt,
    title = {{GDELT}},
    url = {www.gdeltproject.org},
    urldate = {2020-06-24}
}
@misc{pandas,
    title = {{Pandas}},
    url = {pandas.pydata.org/},
    urldate = {2020-06-24}
}
@misc{GDELTDocumentation,
    title = {{GDELT Documentation}},
    url = {https://www.gdeltproject.org/data.html#documentation},
    urldate = {2020-06-15}
}
@misc{pycharm,
    title = {{PyCharm}},
    url = {www.jetbrains.com/pycharm/},
    urldate = {2020-06-24}
}
@misc{iso_alfa3,
    title = {{ISO 3166-1 alfa-3}},
    url = {https://pl.wikipedia.org/wiki/ISO_3166-1_alfa-3},
    urldate = {2020-07-09}
}
@misc{worldbank,
    title = {{World Bank DataBank}},
    url = {databank.worldbank.org},
    urldate = {2020-08-06}
}
@misc{wblicense,
    author = {{World Bank}},
    title = {{World Bank Data License}},
    url = {https://datacatalog.worldbank.org/public-licenses#cc-by},
    urldate = {2020-08-07}
}
@misc{python,
    title = {{Python}},
    url = {www.python.org},
    urldate = {2020-06-24}
}
@article{Schrodt2010,
    abstract = {This paper summarizes the current state-of-the-art for generating$\$nhigh-volume, near-real-time event data using automated coding methods,$\$nbased on recent efforts for the DARPA Integrated Crisis Early Warning$\$nSystem (ICEWS) and NSF-funded research. The ICEWS work expanded by$\$nmore than two orders of magnitude previous automated coding efforts,$\$ncoding of about 26-million sentences generated from 8-million stories$\$ncondensed from around 30 gigabytes of text. The actual coding took$\$nsix minutes. The paper is largely a general "how-to" guide to the$\$npragmatic challenges and solutions to various elements of the process$\$nof generating event data using automated techniques. It also discusses$\$na number of ways that this could be augmented with existing open-source$\$nnatural language processing software to generate a third-generation$\$nevent data coding system.},
    author = {Schrodt, Philip A.},
    isbn = {Version 1.1},
    journal = {American Political Science Association meetings},
    pages = {1--29},
    title = {{Automated Production of High-Volume, Near-Real-Time Political Event Data}},
    url = {http://qipsr.as.uky.edu/sites/default/files/Schrodt.EventData.Princeton2011.pdf},
    year = {2010}
}
@misc{scikit,
    title = {{Scikit-Learn}},
    url = {scikit-learn.org},
    urldate = {2020-06-26}
}
@misc{bigquery,
    title = {{Google BigQuery}},
    url = {cloud.google.com/bigquery},
    urldate = {2020-06-24}
}
@misc{standardScaler,
    title = {{Scikit-Learn StandardScaler}},
    url = {https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html},
    urldate = {2020-07-09}
}
@misc{jupyter,
    title = {{Jupyter Notebook}},
    url = {jupyter.org},
    urldate = {2020-06-24}
}
